{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXyKG1QgbvYU6hjNiYUEoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashutoshgithubs/Insurance_Chatbot/blob/main/Insurance_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit PyPDF2 langchain huggingface-hub sentence-transformers faiss-cpu\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "import getpass\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "if 'HUGGINGFACEHUB_API_TOKEN' not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Please enter your HuggingFace API token: \")\n",
        "\n",
        "# Setting up the Streamlit\n",
        "st.set_page_config(\n",
        "    page_title=\"Insurance Policy AI Assistant\",\n",
        "    page_icon=\"üìÑ\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "\n",
        "# Adding some CSS for better UI ---\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stButton>button {\n",
        "        background-color: #4CAF50;\n",
        "        color: white;\n",
        "        border-radius: 5px;\n",
        "    }\n",
        "    .stTextInput>div>div>input {\n",
        "        border: 1px solid #4CAF50;\n",
        "    }\n",
        "    .sidebar .sidebar-content {\n",
        "        background-color: #f0f2f6;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"üìÑ Insurance Policy AI Assistant\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **insurance policy PDFs**, and I'll answer any questions you have about coverage, premiums, claims, and more.\n",
        "*No pre-loaded data ‚Äì your documents stay private.*\n",
        "\"\"\")\n",
        "\n",
        "# File Upload Section in form of pdf\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"**Upload Insurance Policy PDFs**\",\n",
        "    type=[\"pdf\"],\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "# Now let's process the uploaded files\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def create_knowledge_base(texts):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(texts)\n",
        "\n",
        "    # Generating embeddings.....\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "    return knowledge_base\n",
        "\n",
        "# Let's initialize the Q&A Chain\n",
        "def get_qa_chain(knowledge_base):\n",
        "    prompt_template = \"\"\"\n",
        "    You are an insurance policy expert. Answer ONLY based on the provided context.\n",
        "\n",
        "    **Context:**\n",
        "    {context}\n",
        "\n",
        "    **Question:**\n",
        "    {question}\n",
        "\n",
        "    **Answer clearly and concisely:**\n",
        "    \"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    # Using HuggingFace's Flan-T5 model\n",
        "    llm = HuggingFaceHub(\n",
        "        repo_id=\"google/flan-t5-large\",\n",
        "        model_kwargs={\"temperature\": 0, \"max_length\": 512}\n",
        "    )\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=knowledge_base.as_retriever(),\n",
        "        chain_type_kwargs={\"prompt\": PROMPT},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    return qa_chain\n",
        "\n",
        "\n",
        "if uploaded_files:\n",
        "    # Extracting the texts from all uploaded PDFs\n",
        "    combined_text = \"\"\n",
        "    for file in uploaded_files:\n",
        "        combined_text += extract_text_from_pdf(file)\n",
        "\n",
        "    knowledge_base = create_knowledge_base(combined_text)\n",
        "    qa_chain = get_qa_chain(knowledge_base)\n",
        "\n",
        "    st.success(\"‚úÖ Documents processed! Ask me anything about your policies.\")\n",
        "\n",
        "    # Now creating the Chat Interface\n",
        "    user_question = st.text_input(\"**Ask a question about your policy:**\", placeholder=\"e.g., What's covered in my health insurance?\")\n",
        "\n",
        "    if user_question:\n",
        "        response = qa_chain({\"query\": user_question})\n",
        "\n",
        "        st.subheader(\"Answer:\")\n",
        "        st.write(response[\"result\"])\n",
        "\n",
        "        st.markdown(\"**Source:**\")\n",
        "        st.write(response[\"source_documents\"][0].metadata[\"source\"])\n",
        "else:\n",
        "    st.warning(\"‚ö†Ô∏è Please upload at least one insurance policy PDF to get started.\")\n",
        "\n",
        "# Adding Info. on UI to showcase the working of my chat bot.\n",
        "with st.sidebar:\n",
        "    st.header(\"How It Works\")\n",
        "    st.markdown(\"\"\"\n",
        "    1. **Upload** your insurance policy PDFs\n",
        "    2. The AI **reads & processes** the documents\n",
        "    3. **Ask questions** about coverage, claims, etc.\n",
        "    4. Get **accurate answers** based on your policies\n",
        "    \"\"\")\n",
        "\n",
        "    st.divider()\n",
        "    st.markdown(\"**Note:** Your documents are **not stored** after the session ends.\")"
      ],
      "metadata": {
        "id": "svv54RQSZSY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}